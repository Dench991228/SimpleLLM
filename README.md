# SimpleLLM
A simple Project which aims finetuning LLM with LoRA and QLoRA. And also about serving LLM with vLLM. 

## TODO
1. [x] Finetuning LLM on single GPU with LoRA, using bfloat 16
2. [x] Finetuning LLM on multiple GPU with LoRA, using bfloat 16
3. [x] Finetuning quantized LLM